{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gEVvXRjHLzo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUMSENSE REVIEW — SHORT ANSWERS\n",
        "1) What is k-NN and is it supervised or unsupervised?\n",
        "\n",
        "k-Nearest Neighbors (k-NN) is a supervised learning algorithm that predicts the label of a new data point by looking at the k most similar (closest) labeled examples and taking a majority vote (classification) or an average (regression).\n",
        "\n",
        "2)What is SVM (what does it do) and limitations?\n",
        "\n",
        "Support Vector Machine (SVM) is a supervised classification algorithm that finds the optimal boundary (hyperplane) that maximizes the margin between classes.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Can be computationally expensive for large datasets.\n",
        "\n",
        "Not intuitive to interpret.\n",
        "\n",
        "Performs poorly when classes are highly overlapping.\n",
        "\n",
        "3) How do decision trees work and how do you avoid overfitting?\n",
        "\n",
        "How they work:\n",
        "Decision trees repeatedly split data by choosing the feature that best separates the classes, forming a tree of “if-else” rules.\n",
        "\n",
        "\n",
        "Avoid overfitting:\n",
        "\n",
        "Pruning (remove unnecessary branches)\n",
        "\n",
        "Limit depth\n",
        "\n",
        "Minimum samples per leaf\n",
        "\n",
        "\n",
        "4) Define bootstrap aggregating and ensembling (Random Forests).\n",
        "\n",
        "Ensembling:\n",
        "Combining multiple models to produce a stronger, more stable model.\n",
        "\n",
        "\n",
        "Bootstrap Aggregating (Bagging):\n",
        "\n",
        "Draw many bootstrap samples (samples with replacement).\n",
        "\n",
        "Train a tree on each sample.\n",
        "\n",
        "Average predictions.\n",
        "\n",
        "\n",
        "5) What is backpropagation in neural nets? When do they work best?\n",
        "\n",
        "Backpropagation:\n",
        "A training method where the neural network:\n",
        "\n",
        "Makes a prediction\n",
        "\n",
        "Measures the error\n",
        "\n",
        "Propagates the error backward through layers\n",
        "\n",
        "Updates weights to reduce future error\n",
        "\n",
        "\n",
        "When neural nets work best:\n",
        "\n",
        "Large datasets\n",
        "\n",
        "Complex, nonlinear patterns\n",
        "\n",
        "\n",
        "6) Define the epsilon-decreasing strategy (A/B Testing).\n",
        "\n",
        "In multi-armed bandits, epsilon-decreasing starts by exploring all options (large ε), then slowly reduces ε so the system increasingly exploits the best-performing option.\n",
        "\n",
        "Early: try many versions → gather data\n",
        "\n",
        "Later: show mostly the winner\n",
        "\n",
        "7)List 7 Glossary terms that are interesting.\n",
        "\n",
        "Here are 7 real terms from the Glossary (end of the book) with short meanings:\n",
        "\n",
        "Overfitting — Model fits noise instead of signal.\n",
        "\n",
        "Underfitting — Model too simple; misses patterns.\n",
        "\n",
        "Regularization — Penalizing complexity to prevent overfitting.\n",
        "\n",
        "Lift — Measures true strength of association between items.\n",
        "\n",
        "Principal Component — Weighted combination of variables capturing maximum variance.\n",
        "\n",
        "Bootstrap Sample — Sample drawn with replacement.\n",
        "\n",
        "Confusion Matrix — Table summarizing classification performance.\n",
        "All from Glossary pages\n",
        "\n"
      ],
      "metadata": {
        "id": "jL7bo1UvHMsU"
      }
    }
  ]
}